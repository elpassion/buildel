
callback = fn
  %MessageDelta{} = data ->
    # we received a piece of data
    IO.write(data.content)

  %Message{} = data ->
    # we received the finshed message once fully complete
    IO.puts("")
    IO.puts("")
    IO.inspect(data.content, label: "COMPLETED MESSAGE")
end

custom_fn =
  Function.new!(%{
    name: "query",
    description: "Accepts search query objects array each with query. Break down complex questions into sub-questions. Refine results by criteria, e.g. time / source, don't do this often. Split queries if ResponseTooLargeError occurs.",
    parameters_schema: %{
      type: "object",
      properties: %{
        query: %{
          type: "string",
          description: "The query to search for."
        }
      },
      required: ["query"]
    },
    function: fn %{"query" => query} = _arguments, context ->
      Buildel.HybridDB.query("2_15_document_search_1", query)
      |> Enum.take(5)
      |> Enum.map(fn %{
                      "document" => document,
                      "metadata" => %{"file_name" => filename}
                    } ->
        "File: #{filename}\n\n#{document |> String.trim()}"
      end)
      |> Enum.join("\n\n---\n\n")
    end
  })

LLMChain.new!(%{ llm: ChatOpenAI.new!(%{model: "gpt-4", stream: true}), verbose: true })
|> LLMChain.add_functions(custom_fn)
|> LLMChain.add_message(Message.new_system!("You are a virtual compliance officer. Your job is to answer about procedures that you have documents about.  Use QUERY PLUGIN to get needed documents.

IF THE QUERY PLUGIN RETURNS NO RESULTS OR RESULTS THAT DON'T ALLOW YOU TO FULLY ANSWER THE QUESTION TRY ASKING IT ONE MORE TIME BUT USING SYNONYMS.

If the answer is provided in the document share with me also the context of the document that you have used to answer.

Answer in the same language the question is asked."))
|> LLMChain.add_message(Message.new_user!("Jakie są dozwolone limity wydatków dla klientów?"))
|> LLMChain.run(while_needs_response: true, callback_fn: callback)
